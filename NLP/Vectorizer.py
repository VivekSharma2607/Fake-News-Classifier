# -*- coding: utf-8 -*-
"""Fake News Vectorizer.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Vw-gMe0t8ZXw8H-d4hwVGZ83SPJFr4u3

#Fake News Classifier 
Dataset = https://www.kaggle.com/c/fake-news/overview

**The overview of Dataset**:

**train.csv**: A full training dataset with the following attributes:

* id: unique id for a news article
* title: the title of a news article
* author: author of the news article
* text: the text of the article; could be incomplete
* label: a label that marks the article as potentially unreliable
  * 1: unreliable
  * 0: reliable

**test.csv**: A testing training dataset with all the same attributes at train.csv without the label.

**Sample.csv** : A sample how we could submit our predictions.
"""

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd

"""As performing using NLTK then we need all this necessary file in order to proceed."""

import nltk
nltk.download('stopwords')
nltk.download('wordnet')
nltk.download('punkt')
nltk.download('averaged_perceptron_tagger')

#importing Dataset
df = pd.read_csv('/content/drive/MyDrive/Data/Fake News/train.csv')
df.head()

#Get the Independent features
x = df.drop('label' , axis = 1)
x.head()

#Get the Dependent variable
y = df['label']
y.head()

df.shape

from sklearn.feature_extraction.text import CountVectorizer , HashingVectorizer , TfidfVectorizer

df = df.dropna()

copy = df.copy()

copy.reset_index(inplace = True)

copy['title'][6]

from nltk.corpus import stopwords
from nltk.stem.porter import PorterStemmer
import re
ps = PorterStemmer()
corpus = []
for i in range(0 , len(copy)):
  review = re.sub('[^a-zA-Z]' , ' ',copy['title'][i])
  review = review.lower()
  review = review.split()
  review = [ps.stem(word) for word in review if not word in stopwords.words('english')]
  review = ' '.join(review)
  corpus.append(review)

#Apllying the CountVectorizer
from sklearn.feature_extraction.text import CountVectorizer
cv = CountVectorizer(max_features=5000,ngram_range=(1,3))
X = cv.fit_transform(corpus).toarray()

X.shape

y = copy['label']

#dividing the Dataset into Train and Test
from sklearn.model_selection import  train_test_split
X_train , X_test , y_train , y_test = train_test_split(X, y , test_size = 0.33 , random_state = 1)

cv.get_feature_names()[:20]

cv.get_params()

"""Creating all the feature in Dataframe"""

count_df = pd.DataFrame(X_train , columns = cv.get_feature_names())
count_df.head()

import matplotlib.pyplot as plt

"""A function for plotting the Confusion matrix"""

def plot_confusion_matrix(cm, classes,
                          normalize=False,
                          title='Confusion matrix',
                          cmap=plt.cm.Blues):
    
    plt.imshow(cm, interpolation='nearest', cmap=cmap)
    plt.title(title)
    plt.colorbar()
    tick_marks = np.arange(len(classes))
    plt.xticks(tick_marks, classes, rotation=45)
    plt.yticks(tick_marks, classes)

    if normalize:
        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
        print("Normalized confusion matrix")
    else:
        print('Confusion matrix, without normalization')

    thresh = cm.max() / 2.
    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
        plt.text(j, i, cm[i, j],
                 horizontalalignment="center",
                 color="white" if cm[i, j] > thresh else "black")

    plt.tight_layout()
    plt.ylabel('True label')
    plt.xlabel('Predicted label')

"""#**MultinomialNB Algorithm**"""

from sklearn.naive_bayes import MultinomialNB
classifier = MultinomialNB()

from sklearn import metrics
import numpy as np
import itertools

classifier.fit(X_train , y_train)
pred = classifier.predict(X_test)
score = metrics.accuracy_score(y_test , pred)
print("accuracy: %0.3f" % score)
cm = metrics.confusion_matrix(y_test , pred)
plot_confusion_matrix(cm , classes=['Fake' , 'Real'])

"""#**Passive Aggressive Classifier Algorithm**"""

from sklearn.linear_model import PassiveAggressiveClassifier
linear_clf = PassiveAggressiveClassifier(max_iter = 50)

linear_clf.fit(X_train,y_train)
pred = linear_clf.predict(X_test)
score = metrics.accuracy_score(y_test , pred)
print("accuracy: %0.3f" % score)
cm = metrics.confusion_matrix(y_test , pred)
plot_confusion_matrix(cm , classes=['Fake' , 'Real'])

"""#**Hashing Vectorizer**"""

hs = HashingVectorizer(n_features=5000, alternate_sign=True)
X = hs.fit_transform(corpus).toarray()

X.shape

from sklearn.model_selection import train_test_split
X_train , X_test , y_train , y_test = train_test_split(X,y ,test_size=0.33,random_state=0)

hs.fit(X_train , y_train)
pred = classifier.predict(X_test)
score = metrics.accuracy_score(y_test , pred)
print("Accuracy: %0.3f" % score)
cm = metrics.confusion_matrix(y_test,pred)
plot_confusion_matrix(cm,classes=['Fake' , 'Real'])

"""#**Hyperparameter tunning on MultinomialNB Algorithm**"""

classifier = MultinomialNB(alpha=0.1)

previous_score = 0
for alpha in np.arange(0,1,0.1):
  sub_clf = MultinomialNB(alpha=alpha)
  sub_clf.fit(X_train , y_train)
  y_preds = sub_clf.predict(X_test)
  score = metrics.accuracy_score(y_test,y_preds)
  if score > previous_score:
    classifier = sub_clf
  print("Alpha : {} , Score : {}".format(alpha , score))

#Get features Names
feature = cv.get_feature_names()

classifier.coef_[0]

#Most real
sorted(zip(classifier.coef_[0] , feature) , reverse = True)[:20]

#Most Fake
sorted(zip(classifier.coef_[0] , feature) , reverse=True)[:10]
